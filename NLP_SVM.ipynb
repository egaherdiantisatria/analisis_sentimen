{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_SVM.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMPmlmRDxpICdLUU5sB2Hp4"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tvxWDUC0aOmA"},"source":["1. Mount data ke gdrive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2yQx70e4FRFJ","executionInfo":{"status":"ok","timestamp":1609211301263,"user_tz":-420,"elapsed":1359,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}},"outputId":"9d89353f-9ab4-4cc5-d6bb-37097e4c4576"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3wBrBbgYahnM"},"source":["2. Install Library yang digunakan"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dw4wT0YbOEvg","executionInfo":{"status":"ok","timestamp":1609211305261,"user_tz":-420,"elapsed":5338,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}},"outputId":"9d3d6c70-772f-475b-f87d-5c29e0f85cc9"},"source":["pip install nltk"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTZMB4zWFY2h","executionInfo":{"status":"ok","timestamp":1609211305273,"user_tz":-420,"elapsed":5332,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}},"outputId":"fdb9fd00-0cad-4b9e-897e-99f03f003d6e"},"source":["import pandas as pd # Pandas juga dapat membaca file dari berbagai format seperti .txt, .csv, .tsv, dan lainnya\r\n","import re # ekspresi reguler adalah urutan karakter khusus yang membantu Anda mencocokkan atau menemukan string atau kumpulan string lain\r\n","import string \r\n","import nltk # libray python untuk bekerja dengan permodelan teks\r\n","nltk.download('punkt')\r\n","nltk.download('stopwords')"],"execution_count":37,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"42KSxWaeeBlI"},"source":["3. Menampilkan dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"i4FUImwCFlpU","executionInfo":{"status":"ok","timestamp":1609211305278,"user_tz":-420,"elapsed":5315,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}},"outputId":"d2cd9154-54f0-431a-b6e2-29e4fe133e38"},"source":["df = pd.read_csv(\"gdrive/MyDrive/NLP_Dataset Sentiment Analysis/Womens Clothing E-Commerce Reviews.csv\")\r\n","df.head()"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Clothing ID</th>\n","      <th>Age</th>\n","      <th>Title</th>\n","      <th>Review Text</th>\n","      <th>Rating</th>\n","      <th>Recommended IND</th>\n","      <th>Positive Feedback Count</th>\n","      <th>Division Name</th>\n","      <th>Department Name</th>\n","      <th>Class Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>767</td>\n","      <td>33</td>\n","      <td>NaN</td>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Initmates</td>\n","      <td>Intimate</td>\n","      <td>Intimates</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1080</td>\n","      <td>34</td>\n","      <td>NaN</td>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>General</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1077</td>\n","      <td>60</td>\n","      <td>Some major design flaws</td>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>General</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>1049</td>\n","      <td>50</td>\n","      <td>My favorite buy!</td>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>General Petite</td>\n","      <td>Bottoms</td>\n","      <td>Pants</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>847</td>\n","      <td>47</td>\n","      <td>Flattering shirt</td>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>General</td>\n","      <td>Tops</td>\n","      <td>Blouses</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  Clothing ID  Age  ...   Division Name Department Name  Class Name\n","0           0          767   33  ...       Initmates        Intimate   Intimates\n","1           1         1080   34  ...         General         Dresses     Dresses\n","2           2         1077   60  ...         General         Dresses     Dresses\n","3           3         1049   50  ...  General Petite         Bottoms       Pants\n","4           4          847   47  ...         General            Tops     Blouses\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"gkLKkEjQlCDx","executionInfo":{"status":"ok","timestamp":1609211305281,"user_tz":-420,"elapsed":5293,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}},"outputId":"2497b7b5-d641-44f9-9aac-e8a68ef6f4b2"},"source":["df = df[['Review Text', 'Rating']]\r\n","df.head()"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review Text</th>\n","      <th>Rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         Review Text  Rating\n","0  Absolutely wonderful - silky and sexy and comf...       4\n","1  Love this dress!  it's sooo pretty.  i happene...       5\n","2  I had such high hopes for this dress and reall...       3\n","3  I love, love, love this jumpsuit. it's fun, fl...       5\n","4  This shirt is very flattering to all due to th...       5"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"pCqSHSbSeGp_"},"source":["4. Pelabelan"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"9E0LRj7zlSIK","executionInfo":{"status":"ok","timestamp":1609211305285,"user_tz":-420,"elapsed":5273,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}},"outputId":"399a6b56-ea63-44fb-91b5-eb0f6f78eb90"},"source":["df = df[df.Rating != 3]\r\n","\r\n","pd.set_option('mode.chained_assignment', None)\r\n","df[\"labels\"] = df[\"Rating\"].apply(lambda x: 1 if x < 3  else 0) # positive as 0 and negative as 1\r\n","df = df.drop(\"Rating\",axis=1)\r\n","\r\n","df.head()"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review Text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>I love tracy reese dresses, but this one is no...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         Review Text  labels\n","0  Absolutely wonderful - silky and sexy and comf...       0\n","1  Love this dress!  it's sooo pretty.  i happene...       0\n","3  I love, love, love this jumpsuit. it's fun, fl...       0\n","4  This shirt is very flattering to all due to th...       0\n","5  I love tracy reese dresses, but this one is no...       1"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"fFu0GI94eLJM"},"source":["5. Preprocessing data"]},{"cell_type":"code","metadata":{"id":"VyeTfJwqFqYq","executionInfo":{"status":"ok","timestamp":1609211305290,"user_tz":-420,"elapsed":5261,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}}},"source":["#import stopword - penggunaan stopword yaitu dengan menghapus kata-kata yang memiliki informasi rendah dari sebuah teks\r\n","from nltk.corpus import stopwords \r\n","from nltk.tokenize import sent_tokenize, word_tokenize"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"ajuFZW4IIoQM","executionInfo":{"status":"ok","timestamp":1609211319898,"user_tz":-420,"elapsed":19856,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}},"outputId":"d8f146f8-ef49-4d2f-bf3c-a36756a4e50b"},"source":["def pre_process(Review_Text):\r\n","    # Case Folding: Lowercase\r\n","    # Merubah format teks menjadi format huruf kecil semua (lowercase).\r\n","    Review_Text = str(Review_Text).lower()\r\n","\r\n","    # Case Folding: Removing Number\r\n","    # Menghapus karakter angka.\r\n","    Review_Text = re.sub(r\"\\d+\", \"\", Review_Text)\r\n","\r\n","    # Case Folding: Removing Punctuation\r\n","    # Menghapus karakter tanda baca.\r\n","    Review_Text = Review_Text.translate(str.maketrans(\"\",\"\",string.punctuation))\r\n","\r\n","    #Case Folding: Removing Whitespace\r\n","    #Menghapus karakter kosong.\r\n","    Review_Text = Review_Text.strip()\r\n","\r\n","    \r\n","    #Separating Sentences with Split () Method\r\n","    #Fungsi split() memisahkan string ke dalam list dengan spasi sebagai pemisah jika tidak ditentukan pemisahnya.\r\n","    pisah = Review_Text.split()\r\n","\r\n","    #Tokenizing: Word Tokenizing Using NLTK Module\r\n","    #Menggunakan library NLTK untuk memisahkan kata dalam sebuah kalimat.\r\n","    tokens = nltk.tokenize.word_tokenize(Review_Text)\r\n","\r\n","    #Filtering using NLTK\r\n","    listStopword =  set(stopwords.words('indonesian'))\r\n"," \r\n","    removed = []\r\n","    for t in tokens:\r\n","      if t not in listStopword:\r\n","        removed.append(t)\r\n","\r\n","    return Review_Text\r\n","\r\n","df['Review Text'] = df['Review Text'].apply(lambda x:pre_process(x))\r\n","df.head()"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review Text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>absolutely wonderful  silky and sexy and comfo...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>love this dress  its sooo pretty  i happened t...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>i love love love this jumpsuit its fun flirty ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>this shirt is very flattering to all due to th...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>i love tracy reese dresses but this one is not...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         Review Text  labels\n","0  absolutely wonderful  silky and sexy and comfo...       0\n","1  love this dress  its sooo pretty  i happened t...       0\n","3  i love love love this jumpsuit its fun flirty ...       0\n","4  this shirt is very flattering to all due to th...       0\n","5  i love tracy reese dresses but this one is not...       1"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"zVXdLRrgISpN","executionInfo":{"status":"ok","timestamp":1609211322104,"user_tz":-420,"elapsed":22045,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}}},"source":["#Vectorization\r\n","#Scikit-belajar ini CountVectorizer digunakan untuk mengkonversi koleksi dokumen teks ke vektor istilah / jumlah tanda\r\n","from sklearn.feature_extraction.text import CountVectorizer\r\n","\r\n","# Untuk membuat Count Vectorizer, kita hanya perlu membuatnya.\r\n","# Ada parameter khusus yang dapat kita atur di sini saat membuat vectorizer, tetapi\r\n","# untuk contoh paling dasar, ini tidak diperlukan.\r\n","cv = CountVectorizer()\r\n","# Untuk benar-benar membuat vectorizer, kita hanya perlu memanggil fit pada teks\r\n","# data yang ingin kita perbaiki\r\n","cv.fit(df['Review Text'])\r\n","# Jika kita benar-benar ingin membuat vektor, kita dapat melakukannya dengan memasukkan teks \r\n","# ke dalam vectorizer untuk mendapatkan hitungan mundur\r\n","X = cv.transform(df['Review Text'])\r\n","\r\n","y = df['labels']"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"jRckcyvJmb9K","executionInfo":{"status":"ok","timestamp":1609211322110,"user_tz":-420,"elapsed":22041,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}}},"source":["#Build Classifier\r\n","#sklearn adalah modul Python yang mengintegrasikan algoritme pembelajaran mesin klasik dalam dunia paket Python ilmiah yang erat \r\n","\r\n","from sklearn.linear_model import LogisticRegression\r\n","from sklearn.svm import SVC\r\n","from sklearn.metrics import accuracy_score\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80)"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JNyybyXpPO1V","executionInfo":{"status":"ok","timestamp":1609211327283,"user_tz":-420,"elapsed":27204,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}},"outputId":"57f737a5-c5a6-48bc-ddb9-0d3c6c8b812e"},"source":["#Find the best value of C in logistic regression\r\n","#Regresi Logistik adalah algoritma klasifikasi Pembelajaran Mesin yang digunakan untuk memprediksi probabilitas variabel dependen kategoris\r\n","\r\n","for c in [0.01, 0.05, 0.25, 0.5, 1]:\r\n","    \r\n","    lr = LogisticRegression(C=c)\r\n","    lr.fit(X_train, y_train)\r\n","    print('Accuracy for C=%s: %s'\r\n","         % (c, accuracy_score(y_test, lr.predict(X_test))))"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Accuracy for C=0.01: 0.9090468105748242\n","Accuracy for C=0.05: 0.924812030075188\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy for C=0.25: 0.9272374484598593\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy for C=0.5: 0.9294203250060635\n","Accuracy for C=1: 0.9296628668445307\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9_zBnpGPXvj","executionInfo":{"status":"ok","timestamp":1609211642474,"user_tz":-420,"elapsed":342381,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}},"outputId":"52df92cf-fc3b-45e6-83a3-2f92f5a8c7a7"},"source":["#Find the best value of C in support vector\r\n","#Mesin vektor pendukung (SVM) adalah sekumpulan metode pembelajaran yang diawasi yang digunakan untuk klasifikasi, regresi dan deteksi pencilan\r\n","\r\n","for c in [0.01, 0.05, 0.25, 0.5, 1]:\r\n","    \r\n","    sv = SVC(C=c)\r\n","    sv.fit(X_train, y_train)\r\n","    print('Accuracy for C=%s: %s'\r\n","         % (c, accuracy_score(y_test, sv.predict(X_test))))"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Accuracy for C=0.01: 0.8872180451127819\n","Accuracy for C=0.05: 0.8872180451127819\n","Accuracy for C=0.25: 0.8898860053359204\n","Accuracy for C=0.5: 0.9097744360902256\n","Accuracy for C=1: 0.921173902498181\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YAxgx9AaPgUJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609211644335,"user_tz":-420,"elapsed":344227,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}},"outputId":"4d2e194e-a1e2-4d02-bd82-9ab151e04ae6"},"source":["#Here I choose C=1 to build the final model for Logistic Regression.\r\n","final_model_lr = LogisticRegression(C=1)\r\n","final_model_lr.fit(X, y)\r\n","print('Final Model Accuracy: %s' %accuracy_score(y_test, final_model_lr.predict(X_test)))"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Final Model Accuracy: 0.9776861508610235\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tcm_sC-rQbii","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609211760669,"user_tz":-420,"elapsed":460545,"user":{"displayName":"azzahrah awaliah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh7H2tE5WRt9xCHbf5wicEG9VSgir7Si_koYfwG=s64","userId":"06547510264382728450"}},"outputId":"7dd70725-33e8-4f09-9bdd-50c0b96662b6"},"source":["#Here I choose C=1 to build the final model for Support Vector.\r\n","final_model_sv = SVC(C=1)\r\n","final_model_sv.fit(X, y)\r\n","print('Final Model Accuracy: %s' %accuracy_score(y_test, final_model_sv.predict(X_test)))"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Final Model Accuracy: 0.9650739752607325\n"],"name":"stdout"}]}]}